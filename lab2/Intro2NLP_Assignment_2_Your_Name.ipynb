{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92073528",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing: Assignment 2\n",
    "\n",
    "In this exercise we'll practice training and testing classifiers.\n",
    "\n",
    "- You can use built-in Python packages, scikit-learn and Pandas.\n",
    "- Please comment your code\n",
    "- Submissions are due Sunday at 23:59 **only** on Ilias: **Assignmnets >> Student Submissions >> Assignment 2 (Deadline: 30.04.2023, at 23:59)**\n",
    "\n",
    "- Name the file aproppriately \"Assignment_2_\\<Your_Name\\>.ipynb\".\n",
    "- Please use relative paths, your code should run on my computer if the notebook and the file are both in the same directory.\n",
    "\n",
    "Example: file_name = polarity.txt >> **DON'T use:** /Users/ComputerName/Username/Documents/.../polarity.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5be54",
   "metadata": {},
   "source": [
    "### Task 1.1 (1 point)\n",
    "\n",
    "Create a DataFrame using the `polarity.txt` file and give name to the columns appropriately. (e.g., \"Text\", \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8790350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a259fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mtv films' _election , a high school comedy st...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>did anybody know this film existed a week befo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the plot is deceptively simple .</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george washington carver high school is having...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>it also wrapped production two years ago and h...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>whatever . . . skip</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>it !</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>where's joblo coming from ?</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>a nightmare of elm street 3 ( 7/10 ) - blair w...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text Label\n",
       "0   every now and then a movie comes along from a ...   pos\n",
       "1   mtv films' _election , a high school comedy st...   pos\n",
       "2   did anybody know this film existed a week befo...   pos\n",
       "3                   the plot is deceptively simple .    pos\n",
       "4   george washington carver high school is having...   pos\n",
       "..                                                ...   ...\n",
       "69  it also wrapped production two years ago and h...   neg\n",
       "70                               whatever . . . skip    neg\n",
       "71                                              it !    neg\n",
       "72                       where's joblo coming from ?    neg\n",
       "73  a nightmare of elm street 3 ( 7/10 ) - blair w...   pos\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here comes your code\n",
    "dict = {}\n",
    "texts_list = []\n",
    "label_list = []\n",
    "with open(\"polarity.txt\", \"r\", encoding='utf-8-sig') as infile: \n",
    "    for line in infile: \n",
    "        key, value = line.strip().split(\"\\t\")\n",
    "        texts_list.append(key)\n",
    "        label_list.append(value)\n",
    "\n",
    "dict[\"Text\"] = texts_list\n",
    "dict[\"Label\"] = label_list\n",
    "\n",
    "df = pd.DataFrame(data=dict)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b505bc8",
   "metadata": {},
   "source": [
    "### Task 1.2 (1 point)\n",
    "\n",
    "Create a new column for the DataFrame that contains labels converted to numerical values instead of strings using the function: `apply()` and drop the original column afterwards.\n",
    "\n",
    "Hint: The numarical values can be any meaningful values, e.g., pos >> 1 and neg >> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b671658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here comes your code\n",
    "def converter(input_string):\n",
    "    if input_string == \"pos\":\n",
    "        return 1\n",
    "    elif input_string == \"neg\":\n",
    "        return 0\n",
    "df2 = df\n",
    "df[\"Label\"] = df[\"Label\"].apply(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3686df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mtv films' _election , a high school comedy st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>did anybody know this film existed a week befo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the plot is deceptively simple .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george washington carver high school is having...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>it also wrapped production two years ago and h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>whatever . . . skip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>it !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>where's joblo coming from ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>a nightmare of elm street 3 ( 7/10 ) - blair w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label\n",
       "0   every now and then a movie comes along from a ...      1\n",
       "1   mtv films' _election , a high school comedy st...      1\n",
       "2   did anybody know this film existed a week befo...      1\n",
       "3                   the plot is deceptively simple .       1\n",
       "4   george washington carver high school is having...      1\n",
       "..                                                ...    ...\n",
       "69  it also wrapped production two years ago and h...      0\n",
       "70                               whatever . . . skip       0\n",
       "71                                              it !       0\n",
       "72                       where's joblo coming from ?       0\n",
       "73  a nightmare of elm street 3 ( 7/10 ) - blair w...      1\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb8626",
   "metadata": {},
   "source": [
    "### Bonus point (1 point)\n",
    "\n",
    "Is there any other way of converting strings in the column label to numerical values without using the function: `apply()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b0fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: None, 0: None}\n"
     ]
    }
   ],
   "source": [
    "#here comes your code\n",
    "dict_res = {x: converter(x) for x in df2[\"Label\"].values}\n",
    "print(dict_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53dcdd4c",
   "metadata": {},
   "source": [
    "### Task 2 (4 points)\n",
    "\n",
    "Write a function `create_count_and_probability` that takes a file (`corpus.txt`) as input and returns a csv file as outn_bayesut containing three columns:\n",
    "1. Text\n",
    "2. Count_Vector\n",
    "3. Probability\n",
    "\n",
    "Example:\n",
    "\n",
    "For the line: `This document is the second document.`\n",
    "\n",
    "The row in the csv file should contain:\n",
    "`This document is the second document.`   `[0,2,0,1,0,1,1,0,1]`   `[1/6, 2/6, 1/6, 1/6, 1/6, 2/6]`\n",
    "\n",
    "**Note**:\n",
    "\n",
    "1. You should define your own function and not use e.g., CountVectorizer() which gives you the `count vector`, directly.\n",
    "\n",
    "2. You can either use the whitespace in `split` as the seperator or use the `Regular Expression (re)` to extract the words, as follows:\n",
    "\n",
    "```\n",
    "import re\n",
    "TEXT = \"Hey, - How are you doing today!?\"\n",
    "words_list = re.findall(r\"[\\w']+\", TEXT)\n",
    "print(words_list)\n",
    "```\n",
    "\n",
    "3. To count the words, you can use e.g., the library: `collections`, more specifically `Counter`.\n",
    "\n",
    "4. Please don't upload the outp_bayes_svm_svm_svm_svmut file. Your function should generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687c5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9a7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(line):\n",
    "    words_list = re.findall(r\"[\\w']+\", line)\n",
    "    return [x.lower() for x in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0c375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_count_and_probability(sentence, dictionary):\n",
    "    count_vector = [0] * len(dictionary)\n",
    "    probability = []\n",
    "    probability_lookup = dict.fromkeys(sentence, 0)\n",
    "    for word in sentence:\n",
    "        count_vector[dictionary[word]] += 1\n",
    "        probability_lookup[word] += 1\n",
    "        probability.append(probability_lookup[word]/len(sentence))\n",
    "\n",
    "    return count_vector, probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a09321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_and_probability(file_name):\n",
    "    # here comes your code\n",
    "    words_list = []\n",
    "    sentences = []\n",
    "    original_sentences = []\n",
    "    with open(file_name, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            original_sentences.append(line.strip('\\n'))\n",
    "            words_list.extend(extract_words(line))\n",
    "            sentences.append(extract_words(line))\n",
    "\n",
    "    unique_words = list(dict.fromkeys(words_list))\n",
    "    lookup_dict = {}\n",
    "    for ind, word in enumerate(unique_words):\n",
    "        lookup_dict[word] = ind\n",
    "\n",
    "    d = {\"Text\" : [], \"Count_Vector\" : [], \"Probability\" : []}\n",
    "    Text = []\n",
    "    Count_Vec = []\n",
    "    Prob = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        count_vector, probability = sentence_count_and_probability(sentence, lookup_dict)\n",
    "        Text.append(original_sentences[i])\n",
    "        Count_Vec.append(count_vector)\n",
    "        Prob.append(probability)\n",
    "    \n",
    "    d[\"Text\"] = Text\n",
    "    d[\"Count_Vector\"] = Count_Vec\n",
    "    d[\"Probability\"] = Prob\n",
    "    print(d)\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    df.to_csv(\"corpus_count_and_probability.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11969f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?'], 'Count_Vector': [[1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 0, 2, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0, 0]], 'Probability': [[0.2, 0.2, 0.2, 0.2, 0.2], [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333], [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], [0.2, 0.2, 0.2, 0.2, 0.2]]}\n"
     ]
    }
   ],
   "source": [
    "create_count_and_probability(\"corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e83d094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Count_Vector</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the first document.</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.2, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This document is the second document.</td>\n",
       "      <td>[1, 1, 1, 0, 2, 1, 0, 0, 0]</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And this is the third one.</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this the first document?</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.2, 0.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Text                 Count_Vector   \n",
       "0            This is the first document.  [1, 1, 1, 1, 1, 0, 0, 0, 0]  \\\n",
       "1  This document is the second document.  [1, 1, 1, 0, 2, 1, 0, 0, 0]   \n",
       "2             And this is the third one.  [1, 1, 1, 0, 0, 0, 1, 1, 1]   \n",
       "3            Is this the first document?  [1, 1, 1, 1, 1, 0, 0, 0, 0]   \n",
       "\n",
       "                                         Probability  \n",
       "0                          [0.2, 0.2, 0.2, 0.2, 0.2]  \n",
       "1  [0.16666666666666666, 0.16666666666666666, 0.1...  \n",
       "2  [0.16666666666666666, 0.16666666666666666, 0.1...  \n",
       "3                          [0.2, 0.2, 0.2, 0.2, 0.2]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"corpus_count_and_probability.csv\") #confirmation it works\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41c56eef-5e75-41b5-a05c-f68d0b7d98fd",
   "metadata": {},
   "source": [
    "### Task 3 (4 points)\n",
    "\n",
    "The goal of this task is to train and test classifiers provided in scikit-learn, using two datasets `rural.txt` and `science.txt`.\n",
    "\n",
    "a) Each file (rural and science) contains sentence-wise documents. You should create a dataframe containing two columns: \"Document\" and \" Class\", as shown below. This dataframe will be used later as input for the vectorizer.\n",
    "\n",
    "|Document                             |Class |\n",
    "| ------------------------------------|----- | \n",
    "|PM denies knowledge of AWB kickbacks | rural |\n",
    "|The crocodile ancestor fossil, found...| science |\n",
    "\n",
    " \n",
    "b) Split the data into train (70%) and test (30%) sets and use the tf-idf-vectorizer to train following classifiers provided by scikit-learn:\n",
    "\n",
    "- naive_bayes.GaussianNB()\n",
    "- svm.LinearSVC(). \n",
    "\n",
    "c) Evaluate both classifiers using the test set, report accuracy, recall_bayes, precision, f1 scores and confusion matrix.\n",
    "\n",
    "**Hints:**\n",
    "1. The Gaussian NB Classifier takes a dense matrix as input and the output of the vectorizer is a sparse matrix. Use my_matrix.toarray() for this conversion.\n",
    "2. You can play around with various parameters in both the tf-idf-vectorizer and the classifier to get a better performance in terms of the accuracy. (In the exercise, we will discuss the accuracy of your model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5675827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4b527a-0d04-4a0e-9281-fec9e0cd0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug Chant from the Victorian Farmers Federati...</td>\n",
       "      <td>rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watching a sad movie has about the same effect...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The finding suggests the creation of some seco...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US beef producers have always expected to have...</td>\n",
       "      <td>rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Williams, from the University of Melbourn...</td>\n",
       "      <td>rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matthew O'Sullivan: \"Is there a need to protec...</td>\n",
       "      <td>rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The project is called MatScape and Joachim see...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitochondrial DNA is passed down virtually unc...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pericles probably died of typhoid fever, as di...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>David Pearson from the Department of Conservat...</td>\n",
       "      <td>rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document    Class\n",
       "0  Doug Chant from the Victorian Farmers Federati...    rural\n",
       "1  Watching a sad movie has about the same effect...  science\n",
       "2  The finding suggests the creation of some seco...  science\n",
       "3  US beef producers have always expected to have...    rural\n",
       "4  John Williams, from the University of Melbourn...    rural\n",
       "5  Matthew O'Sullivan: \"Is there a need to protec...    rural\n",
       "6  The project is called MatScape and Joachim see...  science\n",
       "7  Mitochondrial DNA is passed down virtually unc...  science\n",
       "8  Pericles probably died of typhoid fever, as di...  science\n",
       "9  David Pearson from the Department of Conservat...    rural"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here comes your code\n",
    "df = pd.read_csv(\"rural.txt\", sep=\"\\t\", names=[\"Document\", \"Class\"], header=None)\n",
    "df[\"Class\"] = \"rural\"\n",
    "\n",
    "df2 = pd.read_csv(\"science.txt\", sep=\"\\t\", names=[\"Document\", \"Class\"], header=None)\n",
    "df2[\"Class\"] = \"science\"\n",
    "df2.head(13)\n",
    "\n",
    "data = pd.concat([df,df2])\n",
    "data = shuffle(data)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c564a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder = LabelEncoder()\n",
    "# labelencoder.fit(data[\"Class\"])\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913ad5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17da82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder.transform([\"rural\", \"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614bfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Class\"] = labelencoder.transform(data[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19d871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data[\"Document\"], data[\"Class\"], train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dfdc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff4663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_X_train = vectorizer.fit_transform(X_train)\n",
    "dense_X_train = vectorized_X_train.toarray() # creating dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42237bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.LinearSVC()\n",
    "naive_bayes_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0278b541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.fit(dense_X_train, Y_train)\n",
    "naive_bayes_clf.fit(dense_X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "093fad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_X_test = vectorizer.transform(X_test)\n",
    "dense_X_test = vectorized_X_test.toarray()\n",
    "svm_preds = svm_classifier.predict(dense_X_test)\n",
    "bayes_preds = naive_bayes_clf.predict(dense_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fcba37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['science' 'science' 'science' 'rural' 'science' 'rural' 'science'\n",
      " 'science' 'science' 'rural' 'rural' 'rural' 'rural' 'science' 'science'\n",
      " 'rural' 'science' 'science' 'science' 'science' 'science' 'science'\n",
      " 'science' 'science' 'science' 'rural' 'science' 'rural' 'science'\n",
      " 'science' 'science' 'science' 'rural' 'rural' 'rural' 'science' 'science'\n",
      " 'rural' 'rural' 'science' 'rural' 'rural' 'science' 'rural' 'rural'\n",
      " 'science' 'science' 'rural' 'science' 'science' 'rural' 'science'\n",
      " 'science' 'science' 'science' 'science' 'rural' 'rural' 'science' 'rural'\n",
      " 'science' 'rural' 'rural' 'science' 'science' 'rural' 'science' 'science'\n",
      " 'rural' 'science' 'rural' 'rural' 'science' 'science' 'rural' 'science'\n",
      " 'science' 'rural' 'science' 'science' 'science' 'rural' 'science'\n",
      " 'science' 'science' 'science' 'rural' 'science' 'rural' 'science' 'rural'\n",
      " 'science' 'rural' 'science' 'science' 'rural' 'science' 'rural' 'science'\n",
      " 'rural' 'rural' 'science' 'rural' 'science' 'rural' 'rural' 'rural'\n",
      " 'science' 'science' 'science' 'rural' 'science' 'rural' 'science' 'rural'\n",
      " 'rural' 'science' 'science' 'rural' 'rural' 'science' 'rural' 'science'\n",
      " 'rural' 'rural' 'science' 'science' 'rural' 'science' 'science' 'science'\n",
      " 'rural' 'rural' 'science' 'science' 'rural' 'rural' 'rural' 'science'\n",
      " 'science' 'science' 'rural' 'science' 'rural' 'science' 'science' 'rural'\n",
      " 'science' 'rural' 'science' 'science' 'science' 'science' 'science'\n",
      " 'rural' 'science' 'rural' 'rural' 'rural' 'science' 'science' 'rural'\n",
      " 'science' 'science' 'rural' 'science' 'science' 'science' 'science'\n",
      " 'science' 'science' 'science' 'rural' 'science' 'science' 'rural' 'rural'\n",
      " 'science' 'rural' 'rural' 'science' 'science' 'science' 'science' 'rural'\n",
      " 'rural' 'rural' 'rural' 'science' 'rural' 'rural' 'science' 'science'\n",
      " 'science' 'rural' 'rural' 'science' 'rural' 'rural' 'science' 'science'\n",
      " 'rural' 'rural' 'science' 'rural' 'science' 'rural' 'rural' 'rural'\n",
      " 'rural' 'rural' 'science' 'science' 'rural' 'rural' 'rural' 'science'\n",
      " 'science' 'rural' 'rural' 'rural' 'science' 'rural' 'science' 'science'\n",
      " 'science' 'rural' 'science' 'science' 'science' 'science' 'science'\n",
      " 'science' 'science' 'science' 'rural' 'science' 'rural' 'rural' 'science'\n",
      " 'science' 'rural' 'rural' 'science' 'science' 'science' 'science' 'rural'\n",
      " 'rural' 'science' 'rural' 'science' 'rural' 'science' 'science' 'science'\n",
      " 'science' 'rural' 'rural' 'science' 'science' 'science' 'science'\n",
      " 'science' 'rural' 'science' 'rural' 'science' 'science' 'science'\n",
      " 'science' 'science' 'rural' 'rural' 'science' 'science' 'science'\n",
      " 'science' 'science' 'science' 'science' 'rural' 'science' 'science'\n",
      " 'rural' 'rural' 'science' 'rural' 'science' 'rural' 'rural' 'science'\n",
      " 'science' 'rural' 'science' 'rural' 'rural' 'science' 'science' 'rural'\n",
      " 'science' 'rural' 'science' 'rural' 'rural' 'rural']\n"
     ]
    }
   ],
   "source": [
    "print(svm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef14faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Acc: 91.83006535947712\n",
      "Bayes Acc: 91.83006535947712\n"
     ]
    }
   ],
   "source": [
    "correct_answers_svm = np.sum(np.equal(svm_preds, Y_test))\n",
    "svm_accuracy = correct_answers_svm / (len(svm_preds)*1.0) * 100\n",
    "\n",
    "correct_answers_bayes = np.sum(np.equal(bayes_preds, Y_test))\n",
    "bayes_accuracy = correct_answers_bayes / (len(bayes_preds)*1.0) * 100\n",
    "\n",
    "print(f\"SVM Acc: {svm_accuracy}\")\n",
    "print(f\"Bayes Acc: {svm_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b4fa6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svm = confusion_matrix(Y_test, svm_preds, labels=svm_classifier.classes_)\n",
    "tn_svm = cm_svm[0][0]\n",
    "fn_svm = cm_svm[1][0]\n",
    "tp_svm = cm_svm[1][1]\n",
    "fp_svm = cm_svm[0][1]\n",
    "\n",
    "cm_bayes = confusion_matrix(Y_test, bayes_preds, labels=naive_bayes_clf.classes_)\n",
    "tn_bayes = cm_bayes[0][0]\n",
    "fn_bayes = cm_bayes[1][0]\n",
    "tp_bayes = cm_bayes[1][1]\n",
    "fp_bayes = cm_bayes[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94c895e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm = tp_svm/(tp_svm+fp_svm)\n",
    "recall_svm = tp_svm/(tp_svm+fn_svm)\n",
    "F1_SVM = 2*(precision_svm*recall_svm)/(precision_svm+recall_svm)\n",
    "\n",
    "precision_bayes = tp_bayes/(tp_bayes+fp_bayes)\n",
    "recall_bayes = tp_bayes/(tp_bayes+fn_bayes)\n",
    "F1_BAYES = 2*(precision_bayes*recall_bayes)/(precision_bayes+recall_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25410514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Precision: 0.9209039548022598\n",
      "SVM Recall: 0.9367816091954023\n",
      "SVM F1 Score: 0.9287749287749287\n",
      "Bayes Precision: 0.9573170731707317\n",
      "Bayes Recall: 0.9022988505747126\n",
      "Bayes F1 Score: 0.9289940828402367\n"
     ]
    }
   ],
   "source": [
    "print(f\"SVM Precision: {precision_svm}\")\n",
    "print(f\"SVM Recall: {recall_svm}\")\n",
    "print(f\"SVM F1 Score: {F1_SVM}\")\n",
    "print(f\"Bayes Precision: {precision_bayes}\")\n",
    "print(f\"Bayes Recall: {recall_bayes}\")\n",
    "print(f\"Bayes F1 Score: {F1_BAYES}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
